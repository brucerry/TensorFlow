{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Split data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Normalization\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the Insurance Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>smoker</th>\n",
       "      <th>region</th>\n",
       "      <th>charges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>female</td>\n",
       "      <td>27.900</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>southwest</td>\n",
       "      <td>16884.92400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>male</td>\n",
       "      <td>33.770</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>1725.55230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>male</td>\n",
       "      <td>33.000</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>4449.46200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>male</td>\n",
       "      <td>22.705</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>21984.47061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>male</td>\n",
       "      <td>28.880</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>3866.85520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1333</th>\n",
       "      <td>50</td>\n",
       "      <td>male</td>\n",
       "      <td>30.970</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>10600.54830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1334</th>\n",
       "      <td>18</td>\n",
       "      <td>female</td>\n",
       "      <td>31.920</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northeast</td>\n",
       "      <td>2205.98080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1335</th>\n",
       "      <td>18</td>\n",
       "      <td>female</td>\n",
       "      <td>36.850</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>1629.83350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1336</th>\n",
       "      <td>21</td>\n",
       "      <td>female</td>\n",
       "      <td>25.800</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>southwest</td>\n",
       "      <td>2007.94500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1337</th>\n",
       "      <td>61</td>\n",
       "      <td>female</td>\n",
       "      <td>29.070</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>northwest</td>\n",
       "      <td>29141.36030</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1338 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age     sex     bmi  children smoker     region      charges\n",
       "0      19  female  27.900         0    yes  southwest  16884.92400\n",
       "1      18    male  33.770         1     no  southeast   1725.55230\n",
       "2      28    male  33.000         3     no  southeast   4449.46200\n",
       "3      33    male  22.705         0     no  northwest  21984.47061\n",
       "4      32    male  28.880         0     no  northwest   3866.85520\n",
       "...   ...     ...     ...       ...    ...        ...          ...\n",
       "1333   50    male  30.970         3     no  northwest  10600.54830\n",
       "1334   18  female  31.920         0     no  northeast   2205.98080\n",
       "1335   18  female  36.850         0     no  southeast   1629.83350\n",
       "1336   21  female  25.800         0     no  southwest   2007.94500\n",
       "1337   61  female  29.070         0    yes  northwest  29141.36030\n",
       "\n",
       "[1338 rows x 7 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://raw.githubusercontent.com/stedy/Machine-Learning-with-R-datasets/master/insurance.csv'\n",
    "dataset = pd.read_csv(url)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age         0\n",
      "sex         0\n",
      "bmi         0\n",
      "children    0\n",
      "smoker      0\n",
      "region      0\n",
      "charges     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# check unknowns\n",
    "print(dataset.isna().sum())\n",
    "\n",
    "# clean rows with unknowns\n",
    "dataset = dataset.dropna()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-hot from Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset_onehot = pd.get_dummies(dataset)\n",
    "#dataset_onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#features = dataset_onehot.drop('charges', axis='columns')\n",
    "#features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#labels = dataset_onehot['charges']\n",
    "#labels"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = make_column_transformer(\n",
    "    (MinMaxScaler(), ['age', 'bmi', 'children']),\n",
    "    (OneHotEncoder(handle_unknown='ignore'), ['sex', 'smoker', 'region'])\n",
    ")\n",
    "\n",
    "features = dataset.drop('charges', axis='columns')\n",
    "labels = dataset['charges']\n",
    "\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(features, labels, train_size=0.8, random_state=42)\n",
    "\n",
    "# Fit the column\n",
    "ct.fit(train_data)\n",
    "\n",
    "# normalization\n",
    "train_data_normal = ct.transform(train_data)\n",
    "test_data_normal = ct.transform(test_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "34/34 [==============================] - 1s 4ms/step - loss: 13332.0459 - mae: 13332.0459\n",
      "Epoch 2/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 13236.5107 - mae: 13236.5107\n",
      "Epoch 3/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 12991.3252 - mae: 12991.3252\n",
      "Epoch 4/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 12564.8975 - mae: 12564.8975\n",
      "Epoch 5/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 11955.3662 - mae: 11955.3662\n",
      "Epoch 6/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 11216.7061 - mae: 11216.7061\n",
      "Epoch 7/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 10481.0557 - mae: 10481.0557\n",
      "Epoch 8/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 9789.2090 - mae: 9789.2090\n",
      "Epoch 9/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 9180.2881 - mae: 9180.2881\n",
      "Epoch 10/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 8705.8936 - mae: 8705.8936\n",
      "Epoch 11/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 8355.1943 - mae: 8355.1943\n",
      "Epoch 12/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 8109.4521 - mae: 8109.4521\n",
      "Epoch 13/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7947.7690 - mae: 7947.7690\n",
      "Epoch 14/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 7831.1992 - mae: 7831.1992\n",
      "Epoch 15/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 7743.3662 - mae: 7743.3662\n",
      "Epoch 16/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 7663.3735 - mae: 7663.3735\n",
      "Epoch 17/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7587.0010 - mae: 7587.0010\n",
      "Epoch 18/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7511.5400 - mae: 7511.5400\n",
      "Epoch 19/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7434.8589 - mae: 7434.8589\n",
      "Epoch 20/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 7356.0273 - mae: 7356.0273\n",
      "Epoch 21/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7276.6982 - mae: 7276.6982\n",
      "Epoch 22/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7192.0400 - mae: 7192.0400\n",
      "Epoch 23/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7105.0884 - mae: 7105.0884\n",
      "Epoch 24/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7014.3643 - mae: 7014.3643\n",
      "Epoch 25/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 6926.6997 - mae: 6926.6997\n",
      "Epoch 26/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6818.4458 - mae: 6818.4458\n",
      "Epoch 27/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6715.0215 - mae: 6715.0215\n",
      "Epoch 28/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6605.2539 - mae: 6605.2539\n",
      "Epoch 29/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 6489.5317 - mae: 6489.5317\n",
      "Epoch 30/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6367.6934 - mae: 6367.6934\n",
      "Epoch 31/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 6240.4829 - mae: 6240.4829\n",
      "Epoch 32/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6106.8306 - mae: 6106.8306\n",
      "Epoch 33/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5968.2554 - mae: 5968.2554\n",
      "Epoch 34/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5818.1797 - mae: 5818.1797\n",
      "Epoch 35/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5666.0283 - mae: 5666.0283\n",
      "Epoch 36/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5509.4077 - mae: 5509.4077\n",
      "Epoch 37/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5351.6201 - mae: 5351.6201\n",
      "Epoch 38/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 5192.1309 - mae: 5192.1309\n",
      "Epoch 39/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 5029.1528 - mae: 5029.1528\n",
      "Epoch 40/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 4865.2251 - mae: 4865.2251\n",
      "Epoch 41/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 4709.0347 - mae: 4709.0347\n",
      "Epoch 42/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 4557.7183 - mae: 4557.7183\n",
      "Epoch 43/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 4418.9111 - mae: 4418.9111\n",
      "Epoch 44/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 4294.3916 - mae: 4294.3916\n",
      "Epoch 45/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 4183.4673 - mae: 4183.4673\n",
      "Epoch 46/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 4082.4897 - mae: 4082.4897\n",
      "Epoch 47/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3998.4331 - mae: 3998.4331\n",
      "Epoch 48/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3919.2004 - mae: 3919.2004\n",
      "Epoch 49/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3859.8389 - mae: 3859.8389\n",
      "Epoch 50/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3809.6313 - mae: 3809.6313\n",
      "Epoch 51/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3773.0706 - mae: 3773.0706\n",
      "Epoch 52/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3748.1196 - mae: 3748.1196\n",
      "Epoch 53/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3722.5388 - mae: 3722.5388\n",
      "Epoch 54/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3710.3989 - mae: 3710.3989\n",
      "Epoch 55/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3697.3584 - mae: 3697.3584\n",
      "Epoch 56/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3686.2190 - mae: 3686.2190\n",
      "Epoch 57/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3678.9302 - mae: 3678.9302\n",
      "Epoch 58/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3671.2798 - mae: 3671.2798\n",
      "Epoch 59/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3667.0215 - mae: 3667.0215\n",
      "Epoch 60/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3660.5481 - mae: 3660.5481\n",
      "Epoch 61/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3656.2456 - mae: 3656.2456\n",
      "Epoch 62/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3649.5410 - mae: 3649.5410\n",
      "Epoch 63/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3646.2070 - mae: 3646.2070\n",
      "Epoch 64/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3643.6558 - mae: 3643.6558\n",
      "Epoch 65/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3638.7065 - mae: 3638.7065\n",
      "Epoch 66/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3632.9055 - mae: 3632.9055\n",
      "Epoch 67/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3628.9949 - mae: 3628.9949\n",
      "Epoch 68/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3627.0618 - mae: 3627.0618\n",
      "Epoch 69/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3620.1169 - mae: 3620.1169\n",
      "Epoch 70/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3616.8579 - mae: 3616.8579\n",
      "Epoch 71/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3614.0588 - mae: 3614.0586\n",
      "Epoch 72/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3607.2085 - mae: 3607.2085\n",
      "Epoch 73/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3605.1248 - mae: 3605.1248\n",
      "Epoch 74/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3600.7188 - mae: 3600.7188\n",
      "Epoch 75/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3597.2905 - mae: 3597.2905\n",
      "Epoch 76/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3595.4404 - mae: 3595.4404\n",
      "Epoch 77/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3586.4814 - mae: 3586.4814\n",
      "Epoch 78/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3581.2261 - mae: 3581.2261\n",
      "Epoch 79/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3577.6216 - mae: 3577.6216\n",
      "Epoch 80/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3570.3047 - mae: 3570.3047\n",
      "Epoch 81/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3564.1799 - mae: 3564.1799\n",
      "Epoch 82/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3557.7981 - mae: 3557.7981\n",
      "Epoch 83/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3551.6006 - mae: 3551.6006\n",
      "Epoch 84/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3542.7930 - mae: 3542.7930\n",
      "Epoch 85/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3537.2615 - mae: 3537.2615\n",
      "Epoch 86/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3529.9624 - mae: 3529.9624\n",
      "Epoch 87/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3524.7007 - mae: 3524.7007\n",
      "Epoch 88/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3517.6648 - mae: 3517.6648\n",
      "Epoch 89/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3512.2856 - mae: 3512.2856\n",
      "Epoch 90/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3507.0693 - mae: 3507.0693\n",
      "Epoch 91/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3500.4309 - mae: 3500.4309\n",
      "Epoch 92/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3496.1785 - mae: 3496.1785\n",
      "Epoch 93/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3490.4246 - mae: 3490.4246\n",
      "Epoch 94/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3485.2612 - mae: 3485.2612\n",
      "Epoch 95/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3480.3589 - mae: 3480.3589\n",
      "Epoch 96/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3476.9705 - mae: 3476.9705\n",
      "Epoch 97/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3469.1052 - mae: 3469.1052\n",
      "Epoch 98/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3462.0701 - mae: 3462.0701\n",
      "Epoch 99/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3458.9810 - mae: 3458.9810\n",
      "Epoch 100/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3452.2129 - mae: 3452.2129\n",
      "Epoch 101/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3445.0161 - mae: 3445.0161\n",
      "Epoch 102/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3439.6479 - mae: 3439.6479\n",
      "Epoch 103/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3432.6926 - mae: 3432.6926\n",
      "Epoch 104/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3425.7349 - mae: 3425.7349\n",
      "Epoch 105/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3421.7136 - mae: 3421.7136\n",
      "Epoch 106/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3416.9216 - mae: 3416.9216\n",
      "Epoch 107/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3412.1821 - mae: 3412.1821\n",
      "Epoch 108/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3405.9517 - mae: 3405.9517\n",
      "Epoch 109/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3403.0581 - mae: 3403.0581\n",
      "Epoch 110/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3396.5967 - mae: 3396.5967\n",
      "Epoch 111/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3393.8396 - mae: 3393.8396\n",
      "Epoch 112/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3387.9321 - mae: 3387.9321\n",
      "Epoch 113/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3384.3826 - mae: 3384.3826\n",
      "Epoch 114/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3381.4441 - mae: 3381.4441\n",
      "Epoch 115/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3377.7822 - mae: 3377.7822\n",
      "Epoch 116/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3372.4185 - mae: 3372.4185\n",
      "Epoch 117/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3371.0845 - mae: 3371.0845\n",
      "Epoch 118/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3364.6929 - mae: 3364.6929\n",
      "Epoch 119/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3367.0244 - mae: 3367.0244\n",
      "Epoch 120/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3358.3381 - mae: 3358.3381\n",
      "Epoch 121/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3355.1672 - mae: 3355.1672\n",
      "Epoch 122/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3353.8628 - mae: 3353.8628\n",
      "Epoch 123/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3349.1982 - mae: 3349.1982\n",
      "Epoch 124/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3345.2324 - mae: 3345.2324\n",
      "Epoch 125/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3342.9021 - mae: 3342.9021\n",
      "Epoch 126/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3339.1184 - mae: 3339.1184\n",
      "Epoch 127/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3340.7798 - mae: 3340.7798\n",
      "Epoch 128/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3336.5950 - mae: 3336.5950\n",
      "Epoch 129/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3333.7551 - mae: 3333.7551\n",
      "Epoch 130/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3327.0259 - mae: 3327.0259\n",
      "Epoch 131/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3324.9268 - mae: 3324.9268\n",
      "Epoch 132/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3320.5337 - mae: 3320.5337\n",
      "Epoch 133/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3316.3779 - mae: 3316.3779\n",
      "Epoch 134/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3315.0659 - mae: 3315.0659\n",
      "Epoch 135/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3310.9309 - mae: 3310.9309\n",
      "Epoch 136/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3306.9468 - mae: 3306.9468\n",
      "Epoch 137/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3304.7637 - mae: 3304.7637\n",
      "Epoch 138/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3302.9216 - mae: 3302.9216\n",
      "Epoch 139/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3297.2185 - mae: 3297.2185\n",
      "Epoch 140/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3294.2646 - mae: 3294.2646\n",
      "Epoch 141/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3290.7546 - mae: 3290.7546\n",
      "Epoch 142/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3286.8618 - mae: 3286.8618\n",
      "Epoch 143/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3283.7393 - mae: 3283.7393\n",
      "Epoch 144/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3276.8535 - mae: 3276.8535\n",
      "Epoch 145/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3274.8735 - mae: 3274.8735\n",
      "Epoch 146/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3271.5933 - mae: 3271.5933\n",
      "Epoch 147/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3268.0977 - mae: 3268.0977\n",
      "Epoch 148/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3268.1018 - mae: 3268.1018\n",
      "Epoch 149/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3263.0828 - mae: 3263.0828\n",
      "Epoch 150/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3262.1328 - mae: 3262.1328\n",
      "Epoch 151/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3260.1602 - mae: 3260.1602\n",
      "Epoch 152/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3259.9924 - mae: 3259.9924\n",
      "Epoch 153/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3258.1133 - mae: 3258.1133\n",
      "Epoch 154/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3256.8062 - mae: 3256.8062\n",
      "Epoch 155/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3254.8604 - mae: 3254.8604\n",
      "Epoch 156/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3254.1917 - mae: 3254.1917\n",
      "Epoch 157/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3254.9626 - mae: 3254.9626\n",
      "Epoch 158/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3253.5635 - mae: 3253.5635\n",
      "Epoch 159/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3251.2322 - mae: 3251.2322\n",
      "Epoch 160/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3250.0662 - mae: 3250.0662\n",
      "Epoch 161/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3249.2275 - mae: 3249.2275\n",
      "Epoch 162/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3247.5779 - mae: 3247.5779\n",
      "Epoch 163/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 3248.0227 - mae: 3248.0227\n",
      "Epoch 164/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3245.4104 - mae: 3245.4104\n",
      "Epoch 165/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 3244.3125 - mae: 3244.3125\n",
      "Epoch 166/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 3243.8679 - mae: 3243.8679\n",
      "Epoch 167/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3242.8311 - mae: 3242.8311\n",
      "Epoch 168/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3241.3899 - mae: 3241.3899\n",
      "Epoch 169/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3241.2202 - mae: 3241.2202\n",
      "Epoch 170/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3239.8579 - mae: 3239.8579\n",
      "Epoch 171/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3240.7385 - mae: 3240.7385\n",
      "Epoch 172/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3237.8650 - mae: 3237.8650\n",
      "Epoch 173/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 3238.3230 - mae: 3238.3230\n",
      "Epoch 174/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3236.8030 - mae: 3236.8030\n",
      "Epoch 175/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3235.1809 - mae: 3235.1809\n",
      "Epoch 176/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3235.7625 - mae: 3235.7625\n",
      "Epoch 177/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3237.0396 - mae: 3237.0396\n",
      "Epoch 178/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3233.2878 - mae: 3233.2878\n",
      "Epoch 179/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3234.8843 - mae: 3234.8843\n",
      "Epoch 180/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3233.2180 - mae: 3233.2180\n",
      "Epoch 181/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3229.3381 - mae: 3229.3381\n",
      "Epoch 182/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3229.6050 - mae: 3229.6050\n",
      "Epoch 183/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3227.6934 - mae: 3227.6934\n",
      "Epoch 184/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3227.7490 - mae: 3227.7490\n",
      "Epoch 185/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3226.8669 - mae: 3226.8669\n",
      "Epoch 186/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3227.7205 - mae: 3227.7205\n",
      "Epoch 187/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3224.8057 - mae: 3224.8057\n",
      "Epoch 188/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3223.4929 - mae: 3223.4929\n",
      "Epoch 189/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3223.4636 - mae: 3223.4636\n",
      "Epoch 190/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3222.6792 - mae: 3222.6792\n",
      "Epoch 191/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3223.6489 - mae: 3223.6489\n",
      "Epoch 192/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3222.7229 - mae: 3222.7229\n",
      "Epoch 193/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3220.2214 - mae: 3220.2214\n",
      "Epoch 194/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3220.4448 - mae: 3220.4448\n",
      "Epoch 195/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3220.4368 - mae: 3220.4368\n",
      "Epoch 196/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3219.6392 - mae: 3219.6392\n",
      "Epoch 197/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3218.0183 - mae: 3218.0183\n",
      "Epoch 198/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 3219.2102 - mae: 3219.2102\n",
      "Epoch 199/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3219.6255 - mae: 3219.6255\n",
      "Epoch 200/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 3216.1294 - mae: 3216.1294\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(100, activation='relu'),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "    loss='mae',\n",
    "    metrics=['mae']\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    train_data_normal,\n",
    "    train_labels,\n",
    "    epochs=200\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([ 9082.579 ,  5254.495 , 46017.535 ,  9265.7   , 30130.025 ,\n",
       "         4586.5874,  1965.7875, 13901.447 ,  3884.5354, 10210.362 ,\n",
       "        35068.703 ,  7255.9194,  4055.4656, 41044.73  , 44219.59  ,\n",
       "        40776.023 , 10201.5205, 40694.14  ,  8308.283 , 38788.043 ,\n",
       "         5013.355 ,  7501.2495,  1153.9684,  2785.9944, 11021.082 ,\n",
       "        11097.818 , 12673.7705,  5141.868 ,  9699.447 ,   942.2314,\n",
       "         8294.624 , 11864.327 ,  1996.8252,  5693.3667,  3031.7043,\n",
       "         7649.812 ,  2547.2349,  7362.083 , 42363.38  , 36368.906 ,\n",
       "         4354.6104,  2625.636 , 11849.92  , 11905.637 ,  4903.2725,\n",
       "        12192.809 ,  3459.9827,  4396.5415, 39871.223 ,  4524.8823,\n",
       "        13804.944 ,  1486.6987,  6934.3784,  1523.6863, 10847.052 ,\n",
       "        10276.89  ,  3806.7708, 35928.895 , 11941.133 , 10766.131 ,\n",
       "        13633.766 ,  4818.018 , 14146.526 ,  7972.365 , 10369.484 ,\n",
       "         4231.657 , 32536.78  , 10906.142 ,  3653.934 ,  1742.7023,\n",
       "         6121.137 ,  9457.463 ,  8575.518 ,  6377.574 ,  7333.739 ,\n",
       "         4890.914 ,  4887.3687, 11383.861 ,  4417.6714,  9098.802 ,\n",
       "         1329.1442, 45065.414 ,  5193.9663, 33441.58  , 31932.613 ,\n",
       "        41047.438 ,  4867.257 , 10689.941 ,  8308.745 , 11403.469 ,\n",
       "        15046.853 , 45707.96  , 40933.496 ,  5093.2905, 35348.254 ,\n",
       "         6915.141 , 34853.56  ,  1802.8356, 35854.66  ,  6430.48  ,\n",
       "         4617.1743,  1625.3921,  5819.9863, 12425.223 , 12801.762 ,\n",
       "         1498.    ,  7792.913 , 41368.17  ,  1514.6624, 42456.41  ,\n",
       "         1159.2025,  3042.8792, 13006.328 , 36585.926 ,  9872.356 ,\n",
       "         1895.333 , 12566.463 , 39563.89  ,  6330.145 ,  2808.2654,\n",
       "         5617.3154,  7283.297 , 11610.528 ,  2095.5063,  4773.566 ,\n",
       "         7750.227 ,  7442.9165,  9344.585 , 12403.637 ,  1916.8698,\n",
       "         4079.3198,  5944.832 ,  5853.3433,  8123.1016,  5665.1396,\n",
       "        12404.561 ,  4396.8325, 37710.098 , 39398.43  , 37055.81  ,\n",
       "         5246.374 , 10092.276 ,  2475.3828, 11344.254 ,  2266.2532,\n",
       "        41098.38  ,  5261.866 ,  3910.1533, 11512.6   ,  4760.2314,\n",
       "        44063.934 ,  2738.1106,   963.5549, 35428.305 ,  6396.454 ,\n",
       "         4586.0923, 13332.518 ,  8681.66  , 30439.434 , 38163.53  ,\n",
       "        13531.507 ,  2518.0085, 14409.956 ,  2472.378 ,  3557.7644,\n",
       "         7260.3027, 45616.242 , 43701.996 , 39509.145 ,  2770.2927,\n",
       "         9125.163 ,  6260.4717,  5818.359 ,  4328.4194,  2192.9963,\n",
       "        39939.84  , 29741.365 , 13734.587 , 35875.51  , 11673.64  ,\n",
       "        45939.543 ,  3097.0237,  8322.133 ,  5037.7134,  5248.7363,\n",
       "         2938.6035,  4170.4697,  3717.0752,  9033.478 , 10576.788 ,\n",
       "         3566.2944,  2003.9106,  2753.7666, 35137.69  , 13009.671 ,\n",
       "         9625.284 ,  2515.6147, 12089.505 ,  1998.3859,  9021.614 ,\n",
       "         3297.786 , 41390.06  ,  4345.819 ,  2592.5837, 31183.15  ,\n",
       "        33009.12  ,  8828.24  ,  4172.366 ,  8219.133 ,  3297.837 ,\n",
       "        12553.288 , 12005.38  ,  9758.698 , 32208.996 ,  6602.7207,\n",
       "         4285.8906,  4814.365 , 13854.329 , 12512.546 ,  5253.149 ,\n",
       "         2372.1143,  7053.767 ,  6518.6997, 39379.57  ,  2081.1497,\n",
       "        32999.418 ,  1609.3026,  1507.1094,  9566.445 , 11250.334 ,\n",
       "         1526.332 ,  9494.92  ,  4612.621 , 38005.84  ,  9845.467 ,\n",
       "         8490.603 ,  3932.133 ,  6035.7456, 39593.08  ,  1710.726 ,\n",
       "        12846.972 , 34431.527 ,  3131.1782,  3485.0122,  1496.6122,\n",
       "         2840.5813,  4427.8774,  4176.799 , 12937.333 ,  1481.6957,\n",
       "         1817.1134,  7252.868 ,  3332.6626, 11900.1   ,  2529.7947,\n",
       "         3299.1252, 12030.198 ,  3392.0662,  8645.868 ,  6134.007 ,\n",
       "         8051.679 , 13004.585 , 32599.357 , 45123.777 , 12105.909 ,\n",
       "         6078.205 , 42803.99  , 10093.322 ], dtype=float32),\n",
       " 764      9095.06825\n",
       " 887      5272.17580\n",
       " 890     29330.98315\n",
       " 1293     9301.89355\n",
       " 259     33750.29180\n",
       "            ...     \n",
       " 109     47055.53210\n",
       " 575     12222.89830\n",
       " 535      6067.12675\n",
       " 543     63770.42801\n",
       " 846      9872.70100\n",
       " Name: charges, Length: 268, dtype: float64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = model.predict(test_data_normal).flatten()\n",
    "preds, test_labels"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 - 0s - loss: 2875.7063 - mae: 2875.7063 - 203ms/epoch - 23ms/step\n",
      "loss: 2875.706\n",
      "mae: 2875.706\n"
     ]
    }
   ],
   "source": [
    "eval = model.evaluate(test_data_normal, test_labels, verbose=1)\n",
    "\n",
    "for name, value in zip(model.metrics_names, eval):\n",
    "  print(\"%s: %.10f\" % (name, value))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
